# SQL Converter

[![pipeline status](https://gitlab.com/p2m3ng/sql-converter/badges/master/pipeline.svg)](https://gitlab.com/p2m3ng/sql-converter/-/commits/master)
[![coverage report](https://gitlab.com/p2m3ng/sql-converter/badges/master/coverage.svg)](https://gitlab.com/p2m3ng/sql-converter/-/commits/master)

Build simple SQL queries.   
Dump SQL request result in chosen format.

## Presentation

This tool can be used by developers to dump SQL data to various data structures
and export it to JSON or CSV files. 
Dropping database tables becomes easy. 

## Installation

Clone repository: 

    $ git@gitlab.com:p2m3ng/sql-converter.git

Or install with pip:

    $ pip install git+ssh://git@gitlab.com/p2m3ng/sql-converter

Create a virtual environment: 

    $ python3 -m venv venv
    $ source venv/bin/activate
    
Install: 

    $ make install

### Configuration

For database configuration, see: 

    $ sqlconverter config --help

## Usage:

### SQL Query Builder

```python
from sql_converter.query import Query, Table
```

First, declare `Table` and build a `Query`. 

**`name`** is the table name.  
**`fields`** are the requested fields. If the parameter is not set, fields will 
be replaced by a `SELECT *`.  
**`alias`** is the custom alias of the table. The system generates a default 
value which can be overridden if the parameter is filled. 

```python
from sql_converter.query import Table

authors = Table(
    name="author",
    fields=["id", "name", "first_name", "nationality"],
    alias="aut"
)
books = Table(
    name="books",
    fields=["id", "author_id", "title", "isbn"],
    alias="boo",
)
```

Queries objects can be built in chaining arguments. 

```python
from sql_converter.query import Query

query = Query(prettify=False) \
    .add(table=authors) \
    .add(table=books) \
    .join(table1=authors, field1="id", table2=books, field2="author_id", type="") \
    .order_by(table=authors, field="-id") \
    .limit(number=5) \

query.build()
```

By default, fields are protected: 

```sql
SELECT `aut`.`id`, `aut`.`name`, `aut`.`first_name`, `aut`.`nationality`, 
`boo`.`id`, `boo`.`author_id`, `boo`.`title`, `boo`.`isbn` 
FROM `author` AS `aut` 
    INNER JOIN `books` AS `boo` 
        ON `boo`.`author_id` = `aut`.`id` 
ORDER BY `aut`.`id` DESC 
LIMIT 5;
```

The `prettify` parameter prints it in a more readable format: 

```sql
SELECT aut.id, aut.name, aut.first_name, aut.nationality, boo.id, boo.author_id,
boo.title, boo.isbn 
FROM author AS aut 
    INNER JOIN books AS boo 
        ON boo.author_id = aut.id 
ORDER BY aut.id DESC 
LIMIT 5;
```

## SQL Export

### Parameters

```python
from sql_converter.convert import SQLConvert

export = SQLConvert(
    query=query.build(),
    headers=query.headers,
)
```

**`query`** can be a raw SQL query, or be generated by the Query builder. 

**`headers`** is a list of fields. They can be filled when declaring a `Table` 
or embedded in a list of strings. 

**`export_to`** gets file format by its extension (`.csv` or `.json`) or 
returns data as a list of dictionaries if `None`. Default: `None`

```python
export.make(pprint=True, json=False)
```

**`pprint`** print chosen output to console. Default: `False`

**`json`** force output as usable JSON string. Default: `False`

### With Query Builder

```python
export = SQLConvert(
    query=query.build(),
    headers=query.headers,
    export_to=f"authors.csv",
)

data = export.make(pprint=True)
```

### With Raw SQL

Headers are mandatory. 

```python
from sql_converter.convert import SQLConvert

query = """SELECT aut.id, aut.name, aut.first_name, aut.nationality, boo.id, 
boo.author_id, boo.title, boo.isbn 
FROM author AS aut 
    INNER JOIN books AS boo 
        ON boo.author_id = aut.id 
ORDER BY aut.id DESC 
LIMIT 5;"""

headers = ["id", "name", "first_name", "nationality", "id", "author_id", "title", "isbn"]

export = SQLConvert(
    query=query,
    headers=headers,
    export_to=f"authors.json",
)

data = export.make()
```
